Рекомендательная система


Рекомендательная система - это программа, позволяющая предсказать интересные с наибольшей вероятностью объекты (например, книги, фильмы или статьи), уже имея какие-то данные о текущем состоянии. Состоянием могут быть уже понравившееся пользователю объекты, или данные, которые мы знаем о клиенте (например, его музыкальные предпочтения).

Существует три типа рекомендательных систем: коллаборативная фильтрация, фильтрация содержимого (контетная модель) и гибридная модель, которая объединяет предыдущие. 

Попробуем на примере рассмотреть создание рекомендательной системы на основе гибридной модели. Наша задача - рекомендовать новости портала tvrain.ru, имея данные о последних прочитанных статьях. Кроме того, у нас были логи посещений сайта, с помощью которых можно анализировать поведение пользователей, проверять метрики сделанных моделей и рекомендовать статьи на основе исторических данных ("пользователи, которые читают эту статью, также часто читают эти"). 

В нашем случае, получившаяся система должна была получать статьи, которые пользователь прочитал, а также статью, которую он может прочитать и возвращать относительную вероятность того, что после просмотра прочитанных статей, он захочет посмотреть возможную. Далее мы просто проходим по всем статьям, для каждой вычисляем такую вероятность и сортируем по ней.

Так как мы создаем гибридную модель, сначала нам нужно построить коллаборативную фильтрацию и контентную модель. 

Контентная модель рекомендует объекты на основе похожести их содержимого. Например, если пользователь читает новости про кошек, то и рекомендовать стоит похожие статьи.

Существует огромное количество способов построить контетную модель. Изначально мы просто попробовали достать "ключевые слова" из новости - все имена собственные в содержимом, а затем предлагать статьи с наибольшим пересечением ключевых слов. Это уже дало определенный процент "попаданий".

В области построения контентных моделей отдельно стоит тематическое моделирование - способ разбиения документов по темам без учителя. Для этого существует несколько алгоритмов, в нашей системе мы использовали NMF - разложение неотрицательных матриц, она показало себя лучше чем LDA - латентное размещение Дирихле.

Для улучшения работы контетной модели все слова из статей мы предобрабатываем с помощью TF-IDF и переводим в вектора с помощью word2vec. Это помогает нам рассматривать синонимичные слова в новостях.

Прогнав все имеющиеся тексты статей через NMF, мы получили вполне осмысленные темы, например, в один кластер попали статьи про Савченко, в другой - про законы, которые предлагает Госдума.

Теперь каждую новость можно рассматривать как точку в 40-мерном пространстве (всего получилось 40 кластеров), где каждое измерение - это степень принадлежности к какому-то кластеру. Для того, чтобы находить похожие новости мы можем считать Евклидову метрику для каждой возможной рекомендуемой статьи и сортировать по ее возрастанию. 

Это позволяет нам находить наиболее похожие статьи для одной новости, но не учитывает предыдущие статьи. Это мы исправим чуть позже, при построении гибридной модели.

Коллаборативная фильтрация - метод построения прогнозов в рекомендательных системах, при котором используются данные об оценках других пользователей. В конкретном случае, мы говорим не об оценках - для новостей это плохо применимо, а о просмотрах.

В простейшем виде модель коллаборативной фильтрации будет просто считать пересечения просмотров, но у нас такая система рекомендовала наиболее популярные статьи. Следовательно, нужно, чтобы на похожесть новостей не влияла популярность статьи.

Для таких целей часто используется (например, в E-Contenta) косинусная мера - косинус угла между двумя векторами, в данном случае - просмотрами пользователей. [тут нужно спросить у Саши, как косинус сводится к вероятностной формуле, которую он нам написал]

Получившиеся коэффициенты также позволяют нам рекомендовать новость только на основе одной статьи, а не на основе нескольких предыдущих. 

Давайте исправим это в гибридной модели. Пусть она принимает данные о трех последних прочитанных новостей и возможной рекомендуемой новости, а возвращает вероятность, по которой мы и будем сортировать статьи.

Да, все верно, это бинарный классификатор. Мы использовали Random Forest, но результат не сильно меняется от метода к методу.

Наш бинарный классификатор должен объединять две модели, поэтому у него есть две группы фичей: 160 фичей, которые описывают принадлежность к каждой из 40 тем трех последних новостей и возможной новости, а также 3 фичи - косинусная похожесть каждой из трех последних новостей на возможную новость.

После описания всех этих фичей, может сложиться ощущение, что это будет очень долго работать: для каждого пользователя перебирать все новости. Можно еще кэш сделать, а при изменении модели инвалидировать...

На самом деле, нет. Мы проанализировали логи сайта и оказалось, что новость начинает терять актуальность уже через 5 часов после ее выхода. Следовательно, не обязательно перебирать все новости - достаточно найти вероятность того, что новость понравится пользователю, только для статей, вышедших за 24 назад и 24 часа вперед от текущей новости пользователя.

[тут твой график]

В результате у нас получилось небольшое веб-приложение, которые предлагает список новостей в определенный момент времени. Из него можно выбрать статьи и получить для них рекомендации. Нам удавалось найти довольно интересные и неочевидные кейсы. Мы проверили нашу модель с помощью метрики MAP@10 и получили достаточно хороший результат в 0.78.

[скрин нашего аппа]

После этого проекте в GoTo мы поняли некоторые вещи:

- Простую рекомендательную систему сделать совсем не сложно. Если вы разрабатываете свой проект, попробуйте сделать это сами.
- Рекомендательные системы очень часто загоняют пользователя в категории, из которых выхода нет. Например, если пользователь читает статьи про кошек, то модель может не дать новости про собак. А пользователь просто про собак еще не знал. 
В нашем случае, мы рекомендуем новости из недавних, поэтому сильно закрутить в теме просто невозможно. Но, как мы узнали, в других проектах это решается генерацией случайных рекомендаций и наблюдением за пользователем.
