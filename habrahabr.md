
-----------------------------------------------------------------------------------------------------------------------
Одно из основных особенностей школы GoTo - это то, что она направлена на практические применения знаний и каждый ученик (или сразу несколько) в конце смены представляет свой проект, который он разработал за это время.

Мы попросили реальную задачу от одной из компаний партнёров (E-Contenta) - создать рекомендательную систему для новостного портала телеканала. Это было довольно интересной задачей - помимо реальной необходимости такого рода разработок, была еще некоторая уникальность и нетепичность задачи - методы рекомендации новостей в большенстве отличаются от методов рекомендации, допустим, фильмов. После получения задачи мы начали её решать.

-----------------------------------------------------------------------------------------------------------------------

Рекомендательная система - это программа, позволяющая предсказать интересные с наибольшей вероятностью объекты (например, книги, фильмы или статьи), уже имея какие-то данные о текущем состоянии. Состоянием могут быть уже понравившееся пользователю объекты, или данные, которые мы знаем о клиенте (например, его музыкальные предпочтения). Такие данные можно без труда получить с помощью логирования действий пользователя на сайте, собиранием внешней информации о пользователе или об объекте.

Основная задача, которую решает рекомендательная система  - это повышения удобства использования продукта конечному пользователю. Мы должны предсказать, что пользователю понравится с наибольшей вероятностью и тогда он будет избавлен от необходимости искать это самому, что позволит нам удержать пользователя на нашем ресурсе. Благодаря качественным рекомендательным системам выросли такие цифровые гиганты как Netflix, Spotify и многие другие стартапы. 

Среди рекомендательных систем выделяются три основных типа: коллаборативная фильтрация, контетная и гибридная.

Коллаборативная фильтрация - наверное, наиболее популярная модель для рекомендации объектов. Её основная идея в том, что если объекты смотрят почти одинаковые пользователи, то эти объекты стоит рекомендовать друг другу.

![](https://upload.wikimedia.org/wikipedia/commons/5/52/Collaborative_filtering.gif)

Например, если некой Алисе нравится сериалы "Друзья" и "Теория Большого Взрыва", а некому Бобу нравятся "Бруклин 9-9" и "Друзья", то можно порекомендовать "Бруклин 9-9" Алисе и "Теорию Большого Взрыва" Бобу.

Следующий способ построения рекомендательной модели - контетные рекомендации. Это значит, что наша модель будет зависеть от содержимого объектов. Например, можно оценивать похожесть текстов новостей (о том, как именно этот делать - чуть позже) или к фильму "Титаник" рекомендовать другие фильмы Кэмерона. Главная идея этого метода заключается в том, что мы пытаемся достать как можно большую информацию об объекте, который мы хотим порекомендовать, и используем эту информацию для поиска таких же объектов, после чего мы просто рекомендуем похожие объекты.

В нашей задаче по рекоммендации новостей мы решили использовать гибридную модель - она комбинирует результаты предыдущих вариантов и возвращает взвешенный результат.

Наша гибридная модель на основе признаков, которые мы вытащили для объекта и для пользователя возращает вероятность того, что пользователь прочитает эту статью (кликнет на неё). После нескольких тестов, в качестве алгоритма машинного обучения мы решили использовать Random Forest, но это не так принципиально.

Во всех задачах машинного обучения важно посмотреть на распределение данных, построить зависимости, которые помогут тебе обучить модель, без этого хорошего результата получить вы не сможете. Например, в нашей задаче прежде чем написать модель мы построили вот такой график:

![](https://github.com/xenx/recommendation_system/blob/master/graph.png)

Суть гибридной модели в том, что в качестве фичей мы предоставляем ей какие-то значения, полученные с помощью коллаборативной фильтрации и какие-то значения, полученные с помощью контентной модели.

Начнем с коллаборативной фильтрации. Давайте будем вычислять похожесть новостей по пользователям, которые смотрели эту статью. Для этого часто используется косинусная похожесть - косинус угла между двумя векторами, в данном случае - просмотрами пользователей. 

![косинусная похожесть](https://wikimedia.org/api/rest_v1/media/math/render/svg/2a8c50526e2cc7aa837477be87eff1ea703f9dec)

Так как мы хотим, чтобы при рекомендациях учитывалась не только одна новость, возьмем три последние статьи и одну возможную (вероятность перехода на которую мы оцениваем), после чего посчитаем косинусную похожесть от каждой из прочитанных новостей к возможной. Таким образом у нас получится 3 фичи.

Теперь есть более сложная задача - оценивать похожесть новостей по их содержимому. Мы отмели самые простые варианты вроде поиска ключевых слов и подсчета их пересечений из-за маленькой эффективности.

В области построения контентных моделей отдельно стоит тематическое моделирование - способ разбиения документов по темам без учителя. Для этого существует несколько алгоритмов, в нашей системе мы использовали NMF - разложение неотрицательных матриц, она показало себя лучше чем LDA - латентное размещение Дирихле. 

Для улучшения работы контетной модели все слова из статей мы предобрабатываем с помощью TF-IDF и переводим в вектора с помощью word2vec. Это помогает нам рассматривать синонимичные слова в новостях.

Прогнав все имеющиеся тексты статей через NMF, мы получили вполне осмысленные темы, например, в один кластер попали статьи про Савченко, в другой - про законы, которые предлагает Госдума. 

Теперь каждую новость можно рассматривать как точку в 40-мерном пространстве (всего получилось 40 кластеров), где каждое измерение - это степень принадлежности к какому-то кластеру. 
В качестве фичей будем использовать 40 значений для каждой из четырех новостей. Кроме того, можно заняться feature engineering и добавить разность каждой прочитанной статьи с возможной, но этого мы не сделали.

В результате, у нас получилась модель, дающая вполне осмысленные результаты. Например, новостям о возможном назначении кого-нибудь на должность советника Президента по интернету, рекомендуются статьи уже с конкретными именами.

Тем не менее, таких результатов недостаточно и нужно посчитать какую-нибудь метрику качества рекомендаций. Такие метрики очень связаны с оценкой качества ранжирования, поэтому будем использовать MAP@10. Результат - примерно 0.75, что довольно хорошо.

После создания модели, мы собрали веб-приложение с помощью Flask. Его исходники доступны на [Github](https://github.com/xenx/recommendation_system).

За время работы на проектом, мы заметили важную особенность подобных рекомендательных систем: они очень часто загоняют пользователей в ловушку статей на одну и ту же тему, поэтому стоит предусмотреть включения случайных статей, чтобы попробовать найти другие тему, интересные пользователю.
